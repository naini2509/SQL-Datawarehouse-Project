**SQL Data Warehouse Project | End-to-End ETL Architecture**


ğŸ”¹**Overview**:

â”This project demonstrates the design and implementation of a complete Data Warehouse pipeline using Microsoft SQL Server.
It simulates CRM and ERP data integration through a Bronze â†’ Silver â†’ Gold layered architecture, emphasizing data quality, transformation, and reporting readiness.

â”The project showcases advanced SQL skills in data ingestion, cleansing, aggregation, and validation, following industry-standard best practices.



ğŸ”¹**Technologies Used**:

â¤SQL Server / Azure SQL Database

â¤T-SQL (Stored Procedures, DDL, DML, Testing)

â¤CSV Files (Source system simulation)



ğŸ”¹**Project Objectives**:

â¤Ingest structured data from multiple source systems (CRM and ERP).

â¤Apply data quality checks to ensure consistency, accuracy, and completeness.

â¤Transform raw data into cleaned, standardized formats.

â¤Aggregate key business metrics for analytics and reporting.

â¤Build a scalable warehouse structure ready for BI tools.



ğŸ”¹**Key Components**:

| Layer  | Purpose                                                |
| :----- | :----------------------------------------------------- |
| Bronze | Raw data ingestion with minimal transformations.       |
| Silver | Cleaned, deduplicated, and standardized business data. |
| Gold   | Aggregated, analytics-ready datasets for reporting.    |



ğŸ”¹**Process Workflow**:

â– **Database Initialization**:

â¤Setup schema and structure using init_database.sql.

â– **Bronze Layer**:

â¤Create Bronze tables: bronze/ddl_bronze.sql

â¤Load raw CRM and ERP data: bronze/proc_load_bronze.sql

â– **Silver Layer**:

â¤Create Silver tables: silver/ddl_silver.sql

â¤Transform and cleanse data: silver/proc_load_silver.sql

â– **Gold Layer**:

â¤Create Gold tables: gold/ddl_gold.sql

â¤Aggregate metrics for business reporting.

â– **Data Quality Assurance**:

â¤Validate data at Silver and Gold stages using tests/quality_checks_silver.sql and tests/quality_checks_gold.sql.



ğŸ”¹**Business Problems Addressed**:

â– **Data Consistency**: Standardized customer, product, and transaction records.

â– **Inventory Management**: Simulated ERP stock updates post-sales.

â– **Revenue Tracking**: Prepared Gold tables with revenue, profit, and trend metrics.

â– **Anomaly Detection**: Built-in quality checks for missing data and outliers.



ğŸ”¹**Dataset Summary**:

| Source | Files                                                | Description                                                        |
| :----- | :--------------------------------------------------- | :----------------------------------------------------------------- |
| CRM    | `cust_info.csv`, `prd_info.csv`, `sales_details.csv` | Customer profiles, product catalog, and sales transactions.        |
| ERP    | `CUST_AZ12.csv`, `LOC_A101.csv`, `PX_CAT_G1V2.csv`   | Customer master records, location details, and product categories. |




ğŸ”¹**Highlights**:

â¤End-to-End ETL Process designed and built fully with SQL.

â¤Comprehensive Data Cleansing to prepare trusted datasets.

â¤Business-Ready Outputs for seamless BI integration.

â¤Data Validation at multiple layers to ensure integrity.



ğŸ”¹**Future Enhancements**:

â¤Enable real-time data ingestion using streaming architecture.

â¤Integrate predictive analytics for revenue forecasting.

â¤Expand the model to additional business domains (logistics, finance).



ğŸ”¹**About**:

â”This project reflects a real-world Data Engineering and ETL scenario using SQL technologies, demonstrating best practices in data ingestion, cleaning, transformation, validation, and reporting preparation.

â”It serves as a strong portfolio project for roles in Data Engineering, Business Intelligence, and Analytics Engineering.
